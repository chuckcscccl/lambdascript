//Parser generated by rustlr for grammar untyped

#![allow(unused_variables)]
#![allow(non_snake_case)]
#![allow(non_camel_case_types)]
#![allow(unused_parens)]
#![allow(unused_mut)]
#![allow(unused_imports)]
#![allow(unused_assignments)]
#![allow(dead_code)]
#![allow(irrefutable_let_patterns)]
#![allow(unreachable_patterns)]
use std::rc::Rc;
use std::cell::RefCell;
extern crate rustlr;
use rustlr::{Tokenizer,TerminalToken,ZCParser,ZCRProduction,Stateaction,decode_action};
use rustlr::{StrTokenizer,RawToken,LexSource};
use std::collections::{HashMap,HashSet};
use rustlr::{LBox,unbox};
use crate::untyped::*;
use crate::untyped::Term::*;
use fixedstr::str16;

static SYMBOLS:[&'static str;29] = ["_WILDCARD_TOKEN_","lambda","lam","Lam","(",")","[","]","DOT","let","=","in","define","lazy","weak","CBV","Liang",";","INTEGER","ID","T","F","Fs","TOP","Vars","LAMSYM","Ts","START","EOF"];

static TABLE:[u64;214] = [107374444545,8590131200,94489673729,64425099264,12884967424,81605230592,4295098368,90195099649,98784575489,51540525056,111669870593,38655688704,85899870209,77310459904,17180327936,60130197504,281556582334466,563031558914050,844506535690242,1125981512335360,1126002987237377,1407447899242496,1688922875101186,1688931465494528,1688927170723840,1688897105297410,1688867040591872,1688871335493634,1688940055887873,1970333427105792,1970406442205184,1970337721942016,1970419326648321,1970415032074241,1970402147434496,1970329132072960,1970363492663296,1970384967172096,1970342017302528,1970410737696769,1970389262073856,1970432211419137,2251872829177858,2533291970723840,2533364986150913,2533356395626496,2533352100855808,2814827077566464,2814766947434496,2814839962927105,2814831372337152,3096345002901507,3096310643687425,3096284874014720,3096229038915584,3096263399505920,3096332118261761,3096276284342272,3096306349047808,3096237628784640,3096319233490945,3096302054277120,3096314938916865,3096323529637889,3096241924145152,3096233333948416,3096289168916480,3377721195495426,3377772735102978,3377716900528130,3377746965299202,3377781325037570,3377777030070274,3659247711944706,3659221942140930,3659191877369858,3659252006912002,3659196172337154,3659256301879298,3940705510227968,3940731279966208,4222206256807936,4503621102534658,4503676937109506,4503616807567362,4503646872338434,4503681232076802,4503672642142210,4785156209180674,4785108964540418,5066583942365184,5066631187070976,5348076097110018,5348101866913794,5348084687044610,5348037442404354,5348106161881090,5348144816586754,5348088982011906,5348063212208130,5348028852469762,5348041737371650,5348033147437058,5629581138788354,5629572548853762,5629521009246210,5629546779049986,5629516714278914,5629576843821058,5910995987726336,6192496732798978,6192470962995202,6192522502602754,6473971709575170,6473945939771394,6473997479378946,6755472457531392,7036917369536512,7318431001018368,7599867323088896,7881338003587072,7881359478095872,7881303642996736,7881393837572097,7881385249538049,7881376658358272,7881380953128960,7881312232865792,7881307938029568,7881406722342913,7881363772997632,7881389542998017,7881316528226304,8162808685133826,8162855929774082,8444296546418690,8444330906157058,8444322316222466,8444270776614914,8444266481647618,8444326611189762,8725784407638018,8725728573063170,8725775817703426,8725741457965058,8725732868030466,8725762932801538,8725801587507202,8725844537180162,8725805882474498,8725788702605314,8725737162997762,9007237910429696,9007259384938496,9007212139708416,9007216435068928,9007276565200896,9007207844872192,9007293744414721,9007306629185537,9007289449840641,9007203549839360,9007280859971584,9007285156446209,9007263679840256,9288717183549440,9570256582606849,9570157798293504,9570162093129728,9570230813392896,9570235109998593,9570243697836033,9570209338359808,9570239403261953,9570226518622208,9570153503260672,9570166388490240,9570187863851008,9570213633261568,9851671430168578,9851697199972354,9851645660364802,10133172176945154,10414587023261696,10414664333393921,10414591318622208,10414634268491776,10414612793982976,10414638563393536,10414578433392640,10414651448754176,10414681512738817,10414668627968001,10414655743524864,10414582728425472,10414660040196097,10696096362266624,10977597107142658,11259007658557440,11259011953393664,11259016248754176,11259063493525504,11259076378886144,11259089263525889,11259037724114944,11259059198623744,11259084970459137,11259093558099969,11259080673656832,11259003363524608,11259106442870785,11540547060432898,11540521290629122,11540495520825346,];

pub fn make_parser() -> ZCParser<Term,Vec<LBox<Term>>>
{
 let mut parser1:ZCParser<Term,Vec<LBox<Term>>> = ZCParser::new(21,42);
 let mut rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("start");
 rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("Ts");
 rule.Ruleaction = |parser|{ let mut _item1_ = parser.popstack(); let mut x = parser.popstack();  parser.exstate.push(x.lbox()); Nothing };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("Ts");
 rule.Ruleaction = |parser|{ let mut _item2_ = parser.popstack(); let mut x = parser.popstack(); let mut _item0_ = parser.popstack();  parser.exstate.push(x.lbox()); Nothing };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("Fs");
 rule.Ruleaction = |parser|{ let mut _item0_ = parser.popstack(); 
  if let (a,)=(_item0_.value,) {  a }  else {parser.bad_pattern("(a,)")} };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("Fs");
 rule.Ruleaction = |parser|{ let mut b = parser.popstack(); let mut a = parser.popstack();  App(a.lbox(), b.lbox()) };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("F");
 rule.Ruleaction = |parser|{ let mut _item0_ = parser.popstack(); 
  if let ((x),)=(_item0_.value,) {  x } /* var */  else {parser.bad_pattern("((x),)")} };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("F");
 rule.Ruleaction = |parser|{ let mut _item0_ = parser.popstack(); 
  if let ((x),)=(_item0_.value,) {  x } /* const*/  else {parser.bad_pattern("((x),)")} };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("T");
 rule.Ruleaction = |parser|{ let mut _item0_ = parser.popstack(); 
  if let (a,)=(_item0_.value,) {  a }  else {parser.bad_pattern("(a,)")} };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("F");
 rule.Ruleaction = |parser|{ let mut _item2_ = parser.popstack(); let mut _item1_ = parser.popstack(); let mut _item0_ = parser.popstack(); 
  if let (a,)=(_item1_.value,) {  a }  else {parser.bad_pattern("(a,)")} };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("T");
 rule.Ruleaction = |parser|{ let mut x = parser.popstack(); let mut _item0_ = parser.popstack();  CBV(x.lbox()) };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("T");
 rule.Ruleaction = |parser|{ let mut x = parser.popstack(); let mut _item0_ = parser.popstack();  Weak(x.lbox()) };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("T");
 rule.Ruleaction = |parser|{ let mut b = parser.popstack(); let mut _item2_ = parser.popstack(); let mut _item1_ = parser.popstack(); let mut _item0_ = parser.popstack(); 
  if let (Seq(mut vs),)=(_item1_.value,) { 
  let mut t = b.value;
  while vs.len()>0 {
    t = Abs(getvar(&unbox!(vs.pop().unwrap())),parser.lbx(0,t));
  }
  return t; }  else {parser.bad_pattern("(Seq(mut vs),)")} };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("Vars");
 rule.Ruleaction = |parser|{ let mut x = parser.popstack();  Seq(vec![x.lbox()]) };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("Vars");
 rule.Ruleaction = |parser|{ let mut y = parser.popstack(); let mut _item0_ = parser.popstack(); 
  if let (Seq(mut vs),)=(_item0_.value,) {  vs.push(y.lbox()); Seq(vs) }  else {parser.bad_pattern("(Seq(mut vs),)")} };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("T");
 rule.Ruleaction = |parser|{ let mut b = parser.popstack(); let mut _item4_ = parser.popstack(); let mut v = parser.popstack(); let mut _item2_ = parser.popstack(); let mut _item1_ = parser.popstack(); let mut _item0_ = parser.popstack(); 
  if let (Var(x),)=(_item1_.value,) {  App(parser.lbx(0,Abs(x,b.lbox())), v.lbox()) }  else {parser.bad_pattern("(Var(x),)")} };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("TOP");
 rule.Ruleaction = |parser|{ let mut v = parser.popstack(); let mut _item2_ = parser.popstack(); let mut _item1_ = parser.popstack(); let mut _item0_ = parser.popstack(); 
  if let (Var(x),)=(_item1_.value,) { 
  let nv = Def(true,x,v.lbox());
  //parser.exstate.push(parser.lbx(0,nv));
  nv 
 }  else {parser.bad_pattern("(Var(x),)")} };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("TOP");
 rule.Ruleaction = |parser|{ let mut v = parser.popstack(); let mut _item3_ = parser.popstack(); let mut _item2_ = parser.popstack(); let mut _item1_ = parser.popstack(); let mut _item0_ = parser.popstack(); 
  if let (Var(x),)=(_item2_.value,) { 
  let nv = Def(false,x,v.lbox());
  nv 
 }  else {parser.bad_pattern("(Var(x),)")} };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("TOP");
 rule.Ruleaction = |parser|{ let mut _item0_ = parser.popstack(); 
  if let ((x),)=(_item0_.value,) {  x }  else {parser.bad_pattern("((x),)")} };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("LAMSYM");
 rule.Ruleaction = |parser|{ let mut _item0_ = parser.popstack(); <Term>::default()};
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("LAMSYM");
 rule.Ruleaction = |parser|{ let mut _item0_ = parser.popstack(); <Term>::default()};
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("LAMSYM");
 rule.Ruleaction = |parser|{ let mut _item0_ = parser.popstack(); <Term>::default()};
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("START");
 rule.Ruleaction = |parser|{ let mut _item0_ = parser.popstack(); <Term>::default()};
 parser1.Rules.push(rule);
 parser1.Errsym = "";
 parser1.resynch.insert(";");

 for i in 0..214 {
   let symi = ((TABLE[i] & 0x0000ffff00000000) >> 32) as usize;
   let sti = ((TABLE[i] & 0xffff000000000000) >> 48) as usize;
   parser1.RSM[sti].insert(SYMBOLS[symi],decode_action(TABLE[i]));
 }

 for s in SYMBOLS { parser1.Symset.insert(s); }

 load_extras(&mut parser1);
 return parser1;
} //make_parser

pub fn parse_with<'t>(parser:&mut ZCParser<Term,Vec<LBox<Term>>>, lexer:&mut dyn Tokenizer<'t,Term>) -> Result<Term,Term>
{
  let _xres_ = parser.parse(lexer);  if !parser.error_occurred() {Ok(_xres_)} else {Err(_xres_)}
}//parse_with public function

pub fn parse_train_with<'t>(parser:&mut ZCParser<Term,Vec<LBox<Term>>>, lexer:&mut dyn Tokenizer<'t,Term>, parserpath:&str) -> Result<Term,Term>
{
  let _xres_ = parser.parse_train(lexer,parserpath);  if !parser.error_occurred() {Ok(_xres_)} else {Err(_xres_)}
}//parse_train_with public function

// Lexical Scanner using RawToken and StrTokenizer
pub struct untypedlexer<'t> {
   stk: StrTokenizer<'t>,
   keywords: HashSet<&'static str>,
   lexnames: HashMap<&'static str,&'static str>,
   shared_state: Rc<RefCell<Vec<LBox<Term>>>>,
}
impl<'t> untypedlexer<'t> 
{
  pub fn from_str(s:&'t str) -> untypedlexer<'t>  {
    Self::new(StrTokenizer::from_str(s))
  }
  pub fn from_source(s:&'t LexSource<'t>) -> untypedlexer<'t>  {
    Self::new(StrTokenizer::from_source(s))
  }
  pub fn new(mut stk:StrTokenizer<'t>) -> untypedlexer<'t> {
    let mut lexnames = HashMap::with_capacity(64);
    let mut keywords = HashSet::with_capacity(64);
    let shared_state = Rc::new(RefCell::new(<Vec<LBox<Term>>>::default()));
    for kw in ["lazy","_WILDCARD_TOKEN_","Lam","in","lam","CBV","weak","lambda","define","let",] {keywords.insert(kw);}
    for c in ['(',')','[',']','=',';','.',] {stk.add_single(c);}
    for d in [] {stk.add_double(d);}
    for d in [] {stk.add_triple(d);}
    for (k,v) in [(r".","DOT"),] {lexnames.insert(k,v);}
    untypedlexer {stk,keywords,lexnames,shared_state}
  }
}
impl<'t> Tokenizer<'t,Term> for untypedlexer<'t>
{
   fn nextsym(&mut self) -> Option<TerminalToken<'t,Term>> {
    let tokopt = self.stk.next_token();
    if let None = tokopt {return None;}
    let token = tokopt.unwrap();
    match token.0 {
      RawToken::Alphanum(sym) if self.keywords.contains(sym) => {
        let truesym = self.lexnames.get(sym).unwrap_or(&sym);
        Some(TerminalToken::from_raw(token,truesym,<Term>::default()))
      },
      RawToken::Num(n) => Some(TerminalToken::from_raw(token,"INTEGER",Const(n))),
      RawToken::Alphanum("liang") => Some(TerminalToken::from_raw(token,"Liang",Nothing)),
      RawToken::Alphanum(a) => Some(TerminalToken::from_raw(token,"ID",Var(str16::from(a)))),
      RawToken::Symbol(s) if self.lexnames.contains_key(s) => {
        let tname = self.lexnames.get(s).unwrap();
        Some(TerminalToken::from_raw(token,tname,<Term>::default()))
      },
      RawToken::Symbol(s) => Some(TerminalToken::from_raw(token,s,<Term>::default())),
      RawToken::Alphanum(s) => Some(TerminalToken::from_raw(token,s,<Term>::default())),
      _ => Some(TerminalToken::from_raw(token,"<LexicalError>",<Term>::default())),
    }
  }
   fn linenum(&self) -> usize {self.stk.line()}
   fn column(&self) -> usize {self.stk.column()}
   fn position(&self) -> usize {self.stk.current_position()}
   fn current_line(&self) -> &str {self.stk.current_line()}
   fn get_line(&self,i:usize) -> Option<&str> {self.stk.get_line(i)}
   fn get_slice(&self,s:usize,l:usize) -> &str {self.stk.get_slice(s,l)}
}//impl Tokenizer

fn load_extras(parser:&mut ZCParser<Term,Vec<LBox<Term>>>)
{
}//end of load_extras: don't change this line as it affects augmentation
