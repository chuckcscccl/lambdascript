//Parser generated by rustlr for grammar untyped

#![allow(unused_variables)]
#![allow(non_snake_case)]
#![allow(non_camel_case_types)]
#![allow(unused_parens)]
#![allow(unused_mut)]
#![allow(unused_imports)]
#![allow(unused_assignments)]
#![allow(dead_code)]
#![allow(irrefutable_let_patterns)]
#![allow(unreachable_patterns)]
extern crate rustlr;
use rustlr::{Tokenizer,TerminalToken,ZCParser,ZCRProduction,Stateaction,decode_action};
use rustlr::{StrTokenizer,RawToken,LexSource};
use std::collections::{HashMap,HashSet};
use rustlr::{LBox,unbox};
use crate::untyped::*;
use crate::untyped::Term::*;
use fixedstr::str16;

static SYMBOLS:[&'static str;28] = ["lambda","lam","Lam","(",")","[","]","DOT","let","=","in","define","lazy","weak","CBV","Liang",";","INTEGER","ID","T","F","Fs","TOP","Vars","LAMSYM","Ts","START","EOF"];

static TABLE:[u64;214] = [85900001281,524288,47245557760,90194509825,60130328576,103079542785,73015164928,34360721408,8590524416,4296015872,55835426816,12884967424,77309673472,94489673729,107374313473,81604837377,281483567235072,281509337432064,281556582203393,281474977234944,281552286384128,281535107039232,281560876711937,281578056253441,281530812137472,281479272726528,281487861678080,281547991875584,281565171220481,562954249437184,562962838388736,562984314142720,562997198979072,563005788848128,562958543945728,563044443881473,563022968586240,563065917538307,563027263094784,562949953945600,563040147931137,563053032964097,563035853422593,563010083749888,563031558258689,844467880198146,844442110394370,844510830723073,844493650001922,844497945296896,844437815099392,844502239805440,1125912792006658,1125972921548802,1125942856777730,1125977216516098,1125917086973954,1125968626581506,1407452194275328,1407473669177345,1688918581182464,1970393557499906,2251877124210690,2533352101052418,2814792716910594,2814822781681666,2814827076648962,2814762652139522,2814818486714370,2814766947106818,3096237629046786,3096241924014082,3096293463621634,3096302053556226,3096267693817858,3096297758588930,3377772735692800,3377785621381121,3377712605495296,3377777030201344,3659260598157313,3659247712403456,3659252006912000,3659187582205952,3940726985064448,3940701215195136,4222201961840640,4503676937961474,4785091785785344,5066618302169088,5348067507372034,5348041737568258,5348037442600962,5348093277175810,5348101867110402,5348097572143106,5629529599705090,5629576844345346,5911004577726464,5911051822301184,6192462372536322,6192565451751426,6192526797045762,6192483847372802,6192458077569026,6192509617176578,6192496732274690,6192453782601730,6192449487634434,6192522502078466,6192505322209282,6473967414542338,6473941644738562,6473993184346114,6755416621514754,6755442391318530,6755468161122306,7036951729274880,7318388051345408,7599863028121600,7881372362801154,7881376657768450,7881312233259010,7881342298030082,7881368067833858,7881316528226306,8162834454216706,8162774324674562,8162778619641858,8162847339118594,8162787209576450,8162890288791554,8162851634085890,8162830159249410,8162782914609154,8162808684412930,8162821569314818,8444326611517442,8444279366877186,8725801587703808,8725732868554752,8725797293195264,8725805884702721,8725780113457152,8725728574046208,8725758638751744,8725724278554624,8725810178031617,8725814472540161,8725784408358912,8725827357573121,8725737162997760,9007237911805952,9288708592173056,9288678527467520,9288687116419072,9288730066878464,9288751541125120,9288760131452929,9288734361780224,9288777310994433,9288755838255105,9288747246616576,9288674231975936,9288682821976064,9288764425961473,9570162093129728,9570222223327232,9570235108163585,9570157798686720,9570209338490880,9570239402672129,9570153504178176,9570205043589120,9570149208686592,9570230815031297,9570226517835776,9570252287705089,9570183568883712,9851692905005058,9851641365397506,9851667135201282,10133185061584897,10133176471257088,10133202241126401,10133112046551040,10133189356093441,10133107752108032,10133103457599488,10133099162107904,10133172176748544,10133159291912192,10133133522305024,10133154997010432,10133180768518145,10414642858688514,10696092067299328,10977592812175362,11258999068950528,11259054903853056,11259076378099712,11259080675491841,11259059198754816,11259011953393664,11259102147969025,11259033429147648,11259089262936065,11259007658950656,11259084968427521,11259003364442112,11259072083591168,11540491225858050,11540516995661826,11540542765465602,];

pub fn make_parser() -> ZCParser<Term,Vec<LBox<Term>>>
{
 let mut parser1:ZCParser<Term,Vec<LBox<Term>>> = ZCParser::new(21,42);
 let mut rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("start");
 rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("Ts");
 rule.Ruleaction = |parser|{ let mut _item1_ = parser.popstack(); let mut x = parser.popstack();  parser.exstate.push(x.lbox()); Nothing };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("Ts");
 rule.Ruleaction = |parser|{ let mut _item2_ = parser.popstack(); let mut x = parser.popstack(); let mut _item0_ = parser.popstack();  parser.exstate.push(x.lbox()); Nothing };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("Fs");
 rule.Ruleaction = |parser|{ let mut _item0_ = parser.popstack(); 
  if let (a,)=(_item0_.value,) {  a }  else {parser.bad_pattern("(a,)")} };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("Fs");
 rule.Ruleaction = |parser|{ let mut b = parser.popstack(); let mut a = parser.popstack();  App(a.lbox(), b.lbox()) };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("F");
 rule.Ruleaction = |parser|{ let mut _item0_ = parser.popstack(); 
  if let ((x),)=(_item0_.value,) {  x } /* var */  else {parser.bad_pattern("((x),)")} };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("F");
 rule.Ruleaction = |parser|{ let mut _item0_ = parser.popstack(); 
  if let ((x),)=(_item0_.value,) {  x } /* const*/  else {parser.bad_pattern("((x),)")} };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("T");
 rule.Ruleaction = |parser|{ let mut _item0_ = parser.popstack(); 
  if let (a,)=(_item0_.value,) {  a }  else {parser.bad_pattern("(a,)")} };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("F");
 rule.Ruleaction = |parser|{ let mut _item2_ = parser.popstack(); let mut _item1_ = parser.popstack(); let mut _item0_ = parser.popstack(); 
  if let (a,)=(_item1_.value,) {  a }  else {parser.bad_pattern("(a,)")} };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("T");
 rule.Ruleaction = |parser|{ let mut x = parser.popstack(); let mut _item0_ = parser.popstack();  CBV(x.lbox()) };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("T");
 rule.Ruleaction = |parser|{ let mut x = parser.popstack(); let mut _item0_ = parser.popstack();  Weak(x.lbox()) };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("T");
 rule.Ruleaction = |parser|{ let mut b = parser.popstack(); let mut _item2_ = parser.popstack(); let mut _item1_ = parser.popstack(); let mut _item0_ = parser.popstack(); 
  if let (Seq(mut vs),)=(_item1_.value,) { 
  let mut t = b.value;
  while vs.len()>0 {
    t = Abs(getvar(&unbox!(vs.pop().unwrap())),parser.lbx(0,t));
  }
  return t; }  else {parser.bad_pattern("(Seq(mut vs),)")} };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("Vars");
 rule.Ruleaction = |parser|{ let mut x = parser.popstack();  Seq(vec![x.lbox()]) };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("Vars");
 rule.Ruleaction = |parser|{ let mut y = parser.popstack(); let mut _item0_ = parser.popstack(); 
  if let (Seq(mut vs),)=(_item0_.value,) {  vs.push(y.lbox()); Seq(vs) }  else {parser.bad_pattern("(Seq(mut vs),)")} };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("T");
 rule.Ruleaction = |parser|{ let mut b = parser.popstack(); let mut _item4_ = parser.popstack(); let mut v = parser.popstack(); let mut _item2_ = parser.popstack(); let mut _item1_ = parser.popstack(); let mut _item0_ = parser.popstack(); 
  if let (Var(x),)=(_item1_.value,) {  App(parser.lbx(0,Abs(x,b.lbox())), v.lbox()) }  else {parser.bad_pattern("(Var(x),)")} };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("TOP");
 rule.Ruleaction = |parser|{ let mut v = parser.popstack(); let mut _item2_ = parser.popstack(); let mut _item1_ = parser.popstack(); let mut _item0_ = parser.popstack(); 
  if let (Var(x),)=(_item1_.value,) { 
  let nv = Def(true,x,v.lbox());
  //parser.exstate.push(parser.lbx(0,nv));
  nv 
 }  else {parser.bad_pattern("(Var(x),)")} };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("TOP");
 rule.Ruleaction = |parser|{ let mut v = parser.popstack(); let mut _item3_ = parser.popstack(); let mut _item2_ = parser.popstack(); let mut _item1_ = parser.popstack(); let mut _item0_ = parser.popstack(); 
  if let (Var(x),)=(_item2_.value,) { 
  let nv = Def(false,x,v.lbox());
  nv 
 }  else {parser.bad_pattern("(Var(x),)")} };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("TOP");
 rule.Ruleaction = |parser|{ let mut _item0_ = parser.popstack(); 
  if let ((x),)=(_item0_.value,) {  x }  else {parser.bad_pattern("((x),)")} };
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("LAMSYM");
 rule.Ruleaction = |parser|{ let mut _item0_ = parser.popstack(); <Term>::default()};
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("LAMSYM");
 rule.Ruleaction = |parser|{ let mut _item0_ = parser.popstack(); <Term>::default()};
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("LAMSYM");
 rule.Ruleaction = |parser|{ let mut _item0_ = parser.popstack(); <Term>::default()};
 parser1.Rules.push(rule);
 rule = ZCRProduction::<Term,Vec<LBox<Term>>>::new_skeleton("START");
 rule.Ruleaction = |parser|{ let mut _item0_ = parser.popstack(); <Term>::default()};
 parser1.Rules.push(rule);
 parser1.Errsym = "";
 parser1.resynch.insert(";");

 for i in 0..214 {
   let symi = ((TABLE[i] & 0x0000ffff00000000) >> 32) as usize;
   let sti = ((TABLE[i] & 0xffff000000000000) >> 48) as usize;
   parser1.RSM[sti].insert(SYMBOLS[symi],decode_action(TABLE[i]));
 }

 for s in SYMBOLS { parser1.Symset.insert(s); }

 load_extras(&mut parser1);
 return parser1;
} //make_parser


// Lexical Scanner using RawToken and StrTokenizer
pub struct untypedlexer<'t> {
   stk: StrTokenizer<'t>,
   keywords: HashSet<&'static str>,
}
impl<'t> untypedlexer<'t> 
{
  pub fn from_str(s:&'t str) -> untypedlexer<'t>  {
    Self::new(StrTokenizer::from_str(s))
  }
  pub fn from_source(s:&'t LexSource<'t>) -> untypedlexer<'t>  {
    Self::new(StrTokenizer::from_source(s))
  }
  pub fn new(mut stk:StrTokenizer<'t>) -> untypedlexer<'t> {
    let mut keywords = HashSet::with_capacity(16);
    for kw in ["lambda","lam","Lam","let","in","define","lazy","weak","CBV",] {keywords.insert(kw);}
    for c in ['(',')','[',']','=',';','.',] {stk.add_single(c);}
    for d in [] {stk.add_double(d);}
    untypedlexer {stk,keywords}
  }
}
impl<'t> Tokenizer<'t,Term> for untypedlexer<'t>
{
   fn nextsym(&mut self) -> Option<TerminalToken<'t,Term>> {
    let tokopt = self.stk.next_token();
    if let None = tokopt {return None;}
    let token = tokopt.unwrap();
    match token.0 {
      RawToken::Alphanum(sym) if self.keywords.contains(sym) => Some(TerminalToken::from_raw(token,sym,<Term>::default())),
      RawToken::Num(n) => Some(TerminalToken::from_raw(token,"INTEGER",Const(n))),
      RawToken::Alphanum("liang") => Some(TerminalToken::from_raw(token,"Liang",Nothing)),
      RawToken::Alphanum(a) => Some(TerminalToken::from_raw(token,"ID",Var(str16::from(a)))),
      RawToken::Symbol(r".") => Some(TerminalToken::from_raw(token,"DOT",<Term>::default())),
      RawToken::Symbol(s) => Some(TerminalToken::from_raw(token,s,<Term>::default())),
      RawToken::Alphanum(s) => Some(TerminalToken::from_raw(token,s,<Term>::default())),
      _ => Some(TerminalToken::from_raw(token,"<LexicalError>",<Term>::default())),
    }
  }
   fn linenum(&self) -> usize {self.stk.line()}
   fn column(&self) -> usize {self.stk.column()}
   fn position(&self) -> usize {self.stk.current_position()}
}//impl Tokenizer

fn load_extras(parser:&mut ZCParser<Term,Vec<LBox<Term>>>)
{
}//end of load_extras: don't change this line as it affects augmentation
